{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_vector(minmax):\n",
    "    vector = list()\n",
    "    for i in range(len(minmax)):\n",
    "        rand = rand_in_bounds(minmax[i][0], minmax[i][1])\n",
    "        vector.append(rand)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(num_weights):\n",
    "    weights = list()\n",
    "    for i in range(num_weights):\n",
    "        weights.append([-random.random(), random.random()])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activate(weights, vector):\n",
    "    _sum = weights[-1] * 1.0  # I think this is the bias constant\n",
    "    for i in range(len(vector)):\n",
    "        _sum += weights[i] * vector[i]\n",
    "    return _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer(activation):\n",
    "    return 1.0 * (1.0 + Math.exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(network, vector):\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        _input = None\n",
    "        if (i == 0):\n",
    "            _input = vector\n",
    "        else:\n",
    "            new_vector = list()\n",
    "            previous_layer = network[i - 1]\n",
    "            for k in range(len(previous_layer)):\n",
    "                new_vector.append(previous_layer[k])\n",
    "            _input = new_vector\n",
    "        for neuron in layer:\n",
    "            print(neuron[\"weights\"])\n",
    "            neuron[\"activation\"] = activate(neuron[\"weights\"], _input)\n",
    "            neuron[\"output\"] = transfer(neuron[\"activation\"])\n",
    "    return network[-1][0][\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagate_error(network, expected_output):\n",
    "    for i in range(len(network)):\n",
    "        index = len(network) - 1 - i\n",
    "        layer = network[index]\n",
    "        if (index == (len(network) - 1)):\n",
    "            neuron = layer[0] # assume one node in output layer\n",
    "            error = (expected_output - neuron[\"output\"])\n",
    "            neuron[\"delta\"] = error * transfer_derivative(neuron[\"output\"])\n",
    "        else:\n",
    "            next_layer = network[index + 1]\n",
    "            for j in range(len(layer)):\n",
    "                err_sum = 0.0\n",
    "                neuron = layer[j]\n",
    "                for k in range(len(next_layer)):\n",
    "                    next_neuron = next_layer[k]\n",
    "                    err_sum += next_neuron[\"weights\"][j] * next_neuron[\"delta\"]\n",
    "                neuron[\"delta\"] = err_sum * transfer_derivative(neuron[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error_derivatives_for_weights(network, vector):\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        _input = None\n",
    "        if (i == 0):\n",
    "            _input = vector\n",
    "        else:\n",
    "            new_vector = list()\n",
    "            previous_layer = net[i - 1]\n",
    "            for k in range(len(previous_layer)):\n",
    "                new_vector.append(previous_layer[k])\n",
    "            _input = new_vector\n",
    "        for neuron in layer:\n",
    "            signal = None\n",
    "            for k in range(len(_input)):\n",
    "                signal = _input[k]\n",
    "                neuron[\"deriv\"][j] += neuron[\"delta\"] * signal\n",
    "            neuron[\"deriv\"][-1] += neuron[\"delta\"] * 1.0           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(network, learning_rate, mom=0.8):\n",
    "    for layer in network:\n",
    "        for neuron in layer:\n",
    "            for i in range(len(neuron[\"weights\"])):\n",
    "                delta = (learning_rate * neuron[\"deriv\"][i]) + (neuron[\"last_delta\"][i] * mom)\n",
    "                neuron[\"weights\"][i] += delta\n",
    "                neuron[\"last_delta\"][i] = delta\n",
    "                neuron[\"deriv\"][i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(network, domain, num_inputs, iterations, learning_rate):\n",
    "    correct = 0\n",
    "    for epoch in range(iterations):\n",
    "        for pattern in domain:\n",
    "            vector = list()\n",
    "            for k in range(len(pattern)):\n",
    "                vector.append(float(pattern[k]))\n",
    "            expected = pattern[-1]\n",
    "            output = forward_propagate(network, vector)\n",
    "            if (round(output) == expected):\n",
    "                correct += 1\n",
    "            backward_propagate_error(network, expected)\n",
    "            calculate_error_derivatives_for_weights(network, vector)\n",
    "        update_weights(network, learning_rate)\n",
    "        if (((epoch + 1) % 100) == 0):\n",
    "            print(\"> epoch = \" + str(epoch+1) + \", Correct = \" + str(correct) + \"/\" + str(100 * len(domain)))\n",
    "            correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_network(network, domain, num_inputs):\n",
    "    correct = 0\n",
    "    for pattern in domain:\n",
    "        input_vector = list()\n",
    "        for i in range(num_inputs):\n",
    "            input_vector.append(float(pattern[i]))\n",
    "        output = forward_propagate(network, input_vector)\n",
    "        if (round(output) == pattern[-1]):\n",
    "            correct += 1\n",
    "    print(\"Finished test with a score of \" + str(correct) + \"/\" + str(len(domain)))\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_neuron(num_inputs):\n",
    "    neuron = {}\n",
    "    neuron[\"weights\"] = initialize_weights(num_inputs + 1)\n",
    "    neuron[\"last_delta\"] = [0.0] * (num_inputs + 1)\n",
    "    neuron[\"deriv\"] = [0.0] * (num_inputs + 1)\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(domain, num_inputs, iterations, num_nodes, learning_rate):\n",
    "    network = [create_neuron(num_inputs)] * num_nodes\n",
    "    network.append(create_neuron(len(network[-1])))\n",
    "    print(\"Topology: inputs = \" + str(num_inputs) + \"  layers = \" + str(len(network)))\n",
    "    train_network(network, domain, num_inputs, iterations, learning_rate)\n",
    "    test_network(network, domain, num_inputs)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs= 2  layers= 5\n",
      "[{'last_delta': [0.0, 0.0, 0.0], 'deriv': [0.0, 0.0, 0.0], 'weights': [[-0.48057531792158537, 0.4026104457843114], [-0.6148078339430539, 0.35413917254595695], [-0.9853983331634151, 0.31875323415259593]]}, {'last_delta': [0.0, 0.0, 0.0], 'deriv': [0.0, 0.0, 0.0], 'weights': [[-0.48057531792158537, 0.4026104457843114], [-0.6148078339430539, 0.35413917254595695], [-0.9853983331634151, 0.31875323415259593]]}, {'last_delta': [0.0, 0.0, 0.0], 'deriv': [0.0, 0.0, 0.0], 'weights': [[-0.48057531792158537, 0.4026104457843114], [-0.6148078339430539, 0.35413917254595695], [-0.9853983331634151, 0.31875323415259593]]}, {'last_delta': [0.0, 0.0, 0.0], 'deriv': [0.0, 0.0, 0.0], 'weights': [[-0.48057531792158537, 0.4026104457843114], [-0.6148078339430539, 0.35413917254595695], [-0.9853983331634151, 0.31875323415259593]]}, {'last_delta': [0.0, 0.0, 0.0, 0.0], 'deriv': [0.0, 0.0, 0.0, 0.0], 'weights': [[-0.7441463799196603, 0.6225840416500489], [-0.6237180888136289, 0.001838980104451049], [-0.8545198963387994, 0.7023208294603173], [-0.41024811182014487, 0.4666267824157633]]}]\n",
      "last_delta\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-cebe44e1149f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# execute the algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-613ef56c62ec>\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(domain, num_inputs, iterations, num_nodes, learning_rate)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_neuron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Topology: inputs= \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"  layers= \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtest_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-c8f1f81745e6>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(network, domain, num_inputs, iterations, learning_rate)\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mexpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mexpected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-f58a460bb2b1>\u001b[0m in \u001b[0;36mforward_propagate\u001b[1;34m(network, vector)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mneuron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"activation\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"weights\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mneuron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"output\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"activation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"output\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    xor = [[0,0,0], [0,1,1], [1,0,1], [1,1,0]]\n",
    "    inputs = 2\n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    num_hidden_nodes = 4\n",
    "    iterations = 2000\n",
    "    # execute the algorithm\n",
    "    execute(xor, inputs, iterations, num_hidden_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
