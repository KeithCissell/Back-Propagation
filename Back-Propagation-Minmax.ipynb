{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_vector(minmax):\n",
    "    vector = list()\n",
    "    for i in range(len(minmax)):\n",
    "        rand = minmax[i][0] + ((minmax[i][1] - minmax[i][0]) * random.random())\n",
    "        vector.append(rand)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(num_weights):\n",
    "    minmax = list()\n",
    "    for i in range(num_weights):\n",
    "        minmax.append([-random.random(), random.random()])\n",
    "    return random_vector(minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activate(weights, vector):\n",
    "    _sum = weights[-1] * 1.0  # I think this is the bias constant\n",
    "    for i in range(len(vector)):\n",
    "        _sum += weights[i] * vector[i]\n",
    "    return _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer(activation):\n",
    "    return 1.0 * (1.0 + math.exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(network, vector):\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        _input = None\n",
    "        if (i == 0):\n",
    "            _input = vector\n",
    "        else:\n",
    "            new_vector = list()\n",
    "            previous_layer = network[i - 1]\n",
    "            for k in range(len(previous_layer)):\n",
    "                new_vector.append(previous_layer[k][\"output\"])\n",
    "            _input = new_vector\n",
    "        for neuron in layer:\n",
    "            neuron[\"activation\"] = activate(neuron[\"weights\"], _input)\n",
    "            neuron[\"output\"] = transfer(neuron[\"activation\"])\n",
    "    return network[-1][0][\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagate_error(network, expected_output):\n",
    "    for i in range(len(network)):\n",
    "        index = len(network) - 1 - i\n",
    "        layer = network[index]\n",
    "        if (index == (len(network) - 1)):\n",
    "            neuron = layer[0] # assume one node in output layer\n",
    "            error = (expected_output - neuron[\"output\"])\n",
    "            neuron[\"delta\"] = error * transfer_derivative(neuron[\"output\"])\n",
    "        else:\n",
    "            next_layer = network[index + 1]\n",
    "            for j in range(len(layer)):\n",
    "                err_sum = 0.0\n",
    "                neuron = layer[j]\n",
    "                for k in range(len(next_layer)):\n",
    "                    next_neuron = next_layer[k]\n",
    "                    err_sum += next_neuron[\"weights\"][j] * next_neuron[\"delta\"]\n",
    "                neuron[\"delta\"] = err_sum * transfer_derivative(neuron[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error_derivatives_for_weights(network, vector):\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        _input = None\n",
    "        if (i == 0):\n",
    "            _input = vector\n",
    "        else:\n",
    "            new_vector = list()\n",
    "            previous_layer = network[i - 1]\n",
    "            for k in range(len(previous_layer)):\n",
    "                new_vector.append(previous_layer[k][\"output\"])\n",
    "            _input = new_vector\n",
    "        for neuron in layer:\n",
    "            signal = None\n",
    "            for k in range(len(_input)):\n",
    "                signal = _input[k]\n",
    "                neuron[\"deriv\"][k] += neuron[\"delta\"] * signal\n",
    "            neuron[\"deriv\"][-1] += neuron[\"delta\"] * 1.0           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(network, learning_rate, mom=0.8):\n",
    "    for layer in network:\n",
    "        for neuron in layer:\n",
    "            for i in range(len(neuron[\"weights\"])):\n",
    "                delta = (learning_rate * neuron[\"deriv\"][i]) + (neuron[\"last_delta\"][i] * mom)\n",
    "                neuron[\"weights\"][i] += delta\n",
    "                neuron[\"last_delta\"][i] = delta\n",
    "                neuron[\"deriv\"][i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(network, domain, num_inputs, iterations, learning_rate):\n",
    "    correct = 0\n",
    "    for epoch in range(iterations):\n",
    "        for pattern in domain:\n",
    "            vector = list()\n",
    "            for k in range(len(pattern)):\n",
    "                vector.append(float(pattern[k]))\n",
    "            expected = pattern[-1]\n",
    "            output = forward_propagate(network, vector)\n",
    "            if (round(output) == expected):\n",
    "                correct += 1\n",
    "            backward_propagate_error(network, expected)\n",
    "            calculate_error_derivatives_for_weights(network, vector)\n",
    "        update_weights(network, learning_rate)\n",
    "        if (((epoch + 1) % 100) == 0):\n",
    "            print(\"> epoch = \" + str(epoch+1) + \", Correct = \" + str(correct) + \"/\" + str(100 * len(domain)))\n",
    "            print(network[0][0][\"output\"])\n",
    "            correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_network(network, domain, num_inputs):\n",
    "    correct = 0\n",
    "    for pattern in domain:\n",
    "        input_vector = list()\n",
    "        for i in range(num_inputs):\n",
    "            input_vector.append(float(pattern[i]))\n",
    "        output = forward_propagate(network, input_vector)\n",
    "        if (round(output) == pattern[-1]):\n",
    "            correct += 1\n",
    "    print(\"Finished test with a score of \" + str(correct) + \"/\" + str(len(domain)))\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_neuron(num_inputs):\n",
    "    neuron = {}\n",
    "    neuron[\"weights\"] = initialize_weights(num_inputs + 1)\n",
    "    neuron[\"last_delta\"] = [0.0] * (num_inputs + 1)\n",
    "    neuron[\"deriv\"] = [0.0] * (num_inputs + 1)\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(domain, num_inputs, iterations, num_nodes, learning_rate):\n",
    "    network = [[]]\n",
    "    for i in range(num_nodes):\n",
    "        network[0].append(create_neuron(num_inputs))\n",
    "    network.append([create_neuron(len(network[-1]))])\n",
    "    print(\"Topology: inputs = \" + str(num_inputs) + \"  layers = \" + str(len(network)))\n",
    "    train_network(network, domain, num_inputs, iterations, learning_rate)\n",
    "    test_network(network, domain, num_inputs)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 2  layers = 2\n",
      "> epoch = 100, Correct = 200/400\n",
      "2.478766614295832\n",
      "> epoch = 200, Correct = 200/400\n",
      "2.489924514307294\n",
      "> epoch = 300, Correct = 200/400\n",
      "2.500281279220596\n",
      "> epoch = 400, Correct = 200/400\n",
      "2.5099424147289344\n",
      "> epoch = 500, Correct = 200/400\n",
      "2.518993981453246\n",
      "> epoch = 600, Correct = 200/400\n",
      "2.527507084014929\n",
      "> epoch = 700, Correct = 200/400\n",
      "2.5355411372682184\n",
      "> epoch = 800, Correct = 200/400\n",
      "2.5431462884865463\n",
      "> epoch = 900, Correct = 200/400\n",
      "2.5503652441208007\n",
      "> epoch = 1000, Correct = 200/400\n",
      "2.557234668359711\n",
      "> epoch = 1100, Correct = 200/400\n",
      "2.5637862684145563\n",
      "> epoch = 1200, Correct = 200/400\n",
      "2.570047647031915\n",
      "> epoch = 1300, Correct = 200/400\n",
      "2.5760429796118345\n",
      "> epoch = 1400, Correct = 200/400\n",
      "2.5817935574724804\n",
      "> epoch = 1500, Correct = 200/400\n",
      "2.587318227768384\n",
      "> epoch = 1600, Correct = 200/400\n",
      "2.5926337527613272\n",
      "> epoch = 1700, Correct = 200/400\n",
      "2.597755105536531\n",
      "> epoch = 1800, Correct = 200/400\n",
      "2.602695715178128\n",
      "> epoch = 1900, Correct = 200/400\n",
      "2.6074676714137315\n",
      "> epoch = 2000, Correct = 200/400\n",
      "2.6120818965018473\n",
      "Finished test with a score of 2/4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    xor = [[0,0,0], [0,1,1], [1,0,1], [1,1,0]]\n",
    "    inputs = 2\n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    num_hidden_nodes = 4\n",
    "    iterations = 2000\n",
    "    # execute the algorithm\n",
    "    execute(xor, inputs, iterations, num_hidden_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
