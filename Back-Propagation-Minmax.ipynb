{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_vector(minmax):\n",
    "    vector = list()\n",
    "    for i in range(len(minmax)):\n",
    "        rand = minmax[i][0] + ((minmax[i][1] - minmax[i][0]) * random.random())\n",
    "        vector.append(rand)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(num_weights):\n",
    "    minmax = list()\n",
    "    for i in range(num_weights):\n",
    "        minmax.append([-random.random(), random.random()])\n",
    "    return random_vector(minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activate(weights, vector):\n",
    "    _sum = weights[-1] * 1.0  # I think this is the bias constant\n",
    "    for i in range(len(vector)):\n",
    "        _sum += weights[i] * vector[i]\n",
    "    return _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer(activation):\n",
    "    return 1.0 * (1.0 + math.exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(network, vector):\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        _input = None\n",
    "        if (i != (len(network) - 1)):\n",
    "            _input = vector\n",
    "        else:\n",
    "            new_vector = list()\n",
    "            previous_layer = network[i - 1]\n",
    "            for k in range(len(previous_layer)):\n",
    "                new_vector.append(previous_layer[k][\"output\"])\n",
    "            _input = new_vector\n",
    "        for neuron in layer:\n",
    "            neuron[\"activation\"] = activate(neuron[\"weights\"], _input)\n",
    "            neuron[\"output\"] = transfer(neuron[\"activation\"])\n",
    "    return network[-1][0][\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagate_error(network, expected_output):\n",
    "    for i in range(len(network)):\n",
    "        index = len(network) - 1 - i\n",
    "        layer = network[index]\n",
    "        if (index == (len(network) - 1)):\n",
    "            neuron = layer[0] # assume one node in output layer\n",
    "            error = (expected_output - neuron[\"output\"])\n",
    "            neuron[\"delta\"] = error * transfer_derivative(neuron[\"output\"])\n",
    "        else:\n",
    "            next_layer = network[index + 1]\n",
    "            for j in range(len(layer)):\n",
    "                err_sum = 0.0\n",
    "                neuron = layer[j]\n",
    "                for k in range(len(next_layer)):\n",
    "                    next_neuron = next_layer[k]\n",
    "                    err_sum += next_neuron[\"weights\"][j] * next_neuron[\"delta\"]\n",
    "                neuron[\"delta\"] = err_sum * transfer_derivative(neuron[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_error_derivatives_for_weights(network, vector):\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        _input = None\n",
    "        if (i != (len(network) - 1)):\n",
    "            _input = vector\n",
    "        else:\n",
    "            new_vector = list()\n",
    "            previous_layer = network[i - 1]\n",
    "            for k in range(len(previous_layer)):\n",
    "                new_vector.append(previous_layer[k][\"output\"])\n",
    "            _input = new_vector\n",
    "        for neuron in layer:\n",
    "            signal = None\n",
    "            for k in range(len(_input)):\n",
    "                signal = _input[k]\n",
    "                neuron[\"deriv\"][k] += neuron[\"delta\"] * signal\n",
    "            neuron[\"deriv\"][-1] += neuron[\"delta\"] * 1.0           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(network, learning_rate, mom=0.8):\n",
    "    for layer in network:\n",
    "        for neuron in layer:\n",
    "            for i in range(len(neuron[\"weights\"])):\n",
    "                delta = (learning_rate * neuron[\"deriv\"][i]) + (neuron[\"last_delta\"][i] * mom)\n",
    "                neuron[\"weights\"][i] += delta\n",
    "                neuron[\"last_delta\"][i] = delta\n",
    "                neuron[\"deriv\"][i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(network, domain, num_inputs, iterations, learning_rate):\n",
    "    correct = 0\n",
    "    for epoch in range(iterations):\n",
    "        for pattern in domain:\n",
    "            vector = list()\n",
    "            for k in range(num_inputs):\n",
    "                vector.append(float(pattern[k]))\n",
    "            expected = pattern[-1]\n",
    "            output = forward_propagate(network, vector)\n",
    "            if (round(output) == expected):\n",
    "                correct += 1\n",
    "            backward_propagate_error(network, expected)\n",
    "            calculate_error_derivatives_for_weights(network, vector)\n",
    "        update_weights(network, learning_rate)\n",
    "        if (((epoch + 1) % 100) == 0):\n",
    "            print(\"> epoch = \" + str(epoch+1) + \", Correct = \" + str(correct) + \"/\" + str(100 * len(domain)))\n",
    "            #print(network[0][0])\n",
    "            correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_network(network, domain, num_inputs):\n",
    "    correct = 0\n",
    "    for pattern in domain:\n",
    "        input_vector = list()\n",
    "        for i in range(num_inputs):\n",
    "            input_vector.append(float(pattern[i]))\n",
    "        output = forward_propagate(network, input_vector)\n",
    "        if (round(output) == pattern[-1]):\n",
    "            correct += 1\n",
    "    print(\"Finished test with a score of \" + str(correct) + \"/\" + str(len(domain)))\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_neuron(num_inputs):\n",
    "    neuron = {}\n",
    "    neuron[\"weights\"] = initialize_weights(num_inputs + 1)\n",
    "    neuron[\"last_delta\"] = [0.0] * (num_inputs + 1)\n",
    "    neuron[\"deriv\"] = [0.0] * (num_inputs + 1)\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(domain, num_inputs, iterations, num_nodes, learning_rate):\n",
    "    network = [[]]\n",
    "    for i in range(num_nodes):\n",
    "        network[0].append(create_neuron(num_inputs))\n",
    "    network.append([create_neuron(len(network[-1]))])\n",
    "    print(\"Topology: inputs = \" + str(num_inputs) + \"  layers = \" + str(len(network)))\n",
    "    train_network(network, domain, num_inputs, iterations, learning_rate)\n",
    "    test_network(network, domain, num_inputs)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology: inputs = 2  layers = 2\n",
      "> epoch = 100, Correct = 198/400\n",
      "{'activation': -47.37077446111537, 'weights': [-11.71751066520527, -13.05539579870799, -22.597867999583666], 'output': 3.7399513421984924e+20, 'last_delta': [-5.989848201010046e-10, -6.473535081347127e-10, -1.1352234177989961e-09], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 200, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-1.2201536278239928e-19, -1.318682385476756e-19, -2.3124909432339617e-19], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 300, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-2.4854968365325268e-29, -2.6862034605747455e-29, -4.7106272463152733e-29], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 400, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-5.063046475082338e-39, -5.471893088944978e-39, -9.595717171845708e-39], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 500, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-1.0313607819596284e-48, -1.1146443080837026e-48, -1.9546821097780426e-48], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 600, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-2.1009190174322404e-58, -2.270570556382973e-58, -3.9817577799152915e-58], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 700, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-4.279647621874799e-68, -4.62523391015795e-68, -8.11098384673723e-68], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 800, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-8.71779617179334e-78, -9.421767873954025e-78, -1.65223658992717e-77], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 900, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-1.7758464436294174e-87, -1.9192480119916945e-87, -3.3656653750978707e-87], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1000, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-3.6174630941187937e-97, -3.909577247935545e-97, -6.855981453377704e-97], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1100, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-7.368902465782284e-107, -7.96394950630352e-107, -1.3965880873612465e-106], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1200, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-1.5010719428898497e-116, -1.622285165805163e-116, -2.8449001780750447e-116], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1300, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-3.057737550732941e-126, -3.3046532466188897e-126, -5.79516401181928e-126], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1400, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-6.228721397031928e-136, -6.7316975526732774e-136, -1.1804957580834826e-135], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1500, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-1.2688129572318506e-145, -1.3712710096598353e-145, -2.404712329126319e-145], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1600, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-2.5846176411206445e-155, -2.793328379981615e-155, -4.898485527165434e-155], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1700, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-5.264959120031561e-165, -5.690110403738706e-165, -9.978391248389851e-165], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1800, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-1.072491114143471e-174, -1.1590959601730948e-174, -2.0326341958911426e-174], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 1900, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-2.184702983809317e-184, -2.3611201708965716e-184, -4.1405489837580034e-184], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "> epoch = 2000, Correct = 200/400\n",
      "{'activation': -47.37077447302317, 'weights': [-11.717510667601207, -13.055395801297408, -22.597868004124553], 'output': 3.739951386733089e+20, 'last_delta': [-4.450318575624898e-194, -4.8096867325653694e-194, -8.434447241690288e-194], 'deriv': [0.0, 0.0, 0.0], 'delta': -0.0}\n",
      "Finished test with a score of 2/4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # problem configuration\n",
    "    xor = [[0,0,0], [0,1,1], [1,0,1], [1,1,0]]\n",
    "    inputs = 2\n",
    "    # algorithm configuration\n",
    "    learning_rate = 0.3\n",
    "    num_hidden_nodes = 4\n",
    "    iterations = 2000\n",
    "    # execute the algorithm\n",
    "    execute(xor, inputs, iterations, num_hidden_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
